{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mindspore as ms\n",
    "# 导入mindspore中context模块，用于配置当前执行环境，包括执行模式等特性。\n",
    "import mindspore.context as context\n",
    "# c_transforms模块提供常用操作，包括OneHotOp和TypeCast\n",
    "import mindspore.dataset.transforms as C\n",
    "# vision.c_transforms模块是处理图像增强的高性能模块，用于数据增强图像数据改进训练模型。\n",
    "import mindspore.dataset.vision as CV\n",
    "import numpy as np\n",
    "from mindspore import nn\n",
    "from mindspore.nn import Accuracy\n",
    "from mindspore.train import Model\n",
    "from mindspore.train.callback import LossMonitor\n",
    "import matplotlib.pyplot as plt\n",
    "from download import download\n",
    "# 设置MindSpore的执行模式和设备\n",
    "context.set_context(mode=context.GRAPH_MODE, device_target='CPU') # Ascend, CPU, GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/notebook/datasets/MNIST_Data.zip (10.3 MB)\n",
      "\n",
      "file_sizes: 100%|██████████████████████████| 10.8M/10.8M [00:00<00:00, 18.5MB/s]\n",
      "Extracting zip file...\n",
      "Successfully downloaded / unzipped to ./\n"
     ]
    }
   ],
   "source": [
    "url = \"https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/\" \\\n",
    "      \"notebook/datasets/MNIST_Data.zip\"\n",
    "path = download(url, \"./\", kind=\"zip\", replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(data_dir, training=True, batch_size=32, resize=(32, 32),\n",
    "                   rescale=1/(255*0.3081), shift=-0.1307/0.3081, buffer_size=64):\n",
    "    data_train = os.path.join(data_dir, 'train') # 训练集信息\n",
    "    data_test = os.path.join(data_dir, 'test') # 测试集信息\n",
    "    ds = ms.dataset.MnistDataset(data_train if training else data_test)\n",
    "    ds = ds.map(input_columns=[\"image\"], operations=[CV.Resize(resize), CV.Rescale(rescale, shift), CV.HWC2CHW()])\n",
    "    ds = ds.map(input_columns=[\"label\"], operations=C.TypeCast(ms.int32))\n",
    "    ds = ds.shuffle(buffer_size=buffer_size).batch(batch_size, drop_remainder=True)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Cell):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        #设置卷积网络（输入输出通道数，卷积核尺寸，步长，填充方式）\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5, stride=1, pad_mode='valid')\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5, stride=1, pad_mode='valid')\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Dense(400, 120)\n",
    "        self.fc2 = nn.Dense(120, 84)\n",
    "        self.fc3 = nn.Dense(84, 10)\n",
    "    #构建网络\n",
    "    def construct(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_dir, lr=0.01, momentum=0.9, num_epochs=5):\n",
    "    ds_train = create_dataset(data_dir)\n",
    "    ds_eval = create_dataset(data_dir, training=False)\n",
    "    net = LeNet5()\n",
    "    #计算softmax交叉熵。\n",
    "    loss = nn.loss.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\n",
    "    #设置Momentum优化器\n",
    "    opt = nn.Momentum(net.trainable_params(), lr, momentum)\n",
    "    loss_cb = LossMonitor(per_print_times=ds_train.get_dataset_size())\n",
    "    metrics = {\"Accuracy\": Accuracy(), \"Confusion_matrix\": nn.ConfusionMatrix(num_classes=10)}\n",
    "    model = Model(net, loss, opt, metrics)\n",
    "    model.train(num_epochs, ds_train, callbacks=[loss_cb], dataset_sink_mode=True)\n",
    "    metrics_result = model.eval(ds_eval)\n",
    "    res = metrics_result[\"Confusion_matrix\"]\n",
    "    print('Accuracy:',metrics_result[\"Accuracy\"])\n",
    "    print('Confusion_matrix:', res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 1875, loss is 0.0660281628370285\n",
      "epoch: 2 step: 1875, loss is 0.0023815338499844074\n",
      "epoch: 3 step: 1875, loss is 0.19258147478103638\n",
      "epoch: 4 step: 1875, loss is 0.04538374021649361\n",
      "epoch: 5 step: 1875, loss is 0.062643863260746\n",
      "Accuracy: 0.98828125\n",
      "Confusion_matrix: [[9.720e+02 1.000e+00 1.000e+00 0.000e+00 0.000e+00 1.000e+00 1.000e+00\n",
      "  0.000e+00 0.000e+00 2.000e+00]\n",
      " [0.000e+00 1.124e+03 2.000e+00 3.000e+00 1.000e+00 1.000e+00 0.000e+00\n",
      "  1.000e+00 0.000e+00 0.000e+00]\n",
      " [0.000e+00 1.000e+00 1.026e+03 0.000e+00 4.000e+00 0.000e+00 0.000e+00\n",
      "  1.000e+00 0.000e+00 0.000e+00]\n",
      " [0.000e+00 0.000e+00 3.000e+00 1.005e+03 0.000e+00 0.000e+00 0.000e+00\n",
      "  1.000e+00 1.000e+00 0.000e+00]\n",
      " [0.000e+00 0.000e+00 0.000e+00 0.000e+00 9.730e+02 0.000e+00 2.000e+00\n",
      "  0.000e+00 0.000e+00 4.000e+00]\n",
      " [1.000e+00 0.000e+00 2.000e+00 1.100e+01 1.000e+00 8.690e+02 1.000e+00\n",
      "  1.000e+00 0.000e+00 6.000e+00]\n",
      " [3.000e+00 2.000e+00 1.000e+00 1.000e+00 3.000e+00 1.000e+00 9.450e+02\n",
      "  0.000e+00 0.000e+00 0.000e+00]\n",
      " [1.000e+00 0.000e+00 5.000e+00 1.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "  1.013e+03 0.000e+00 8.000e+00]\n",
      " [5.000e+00 0.000e+00 6.000e+00 1.000e+00 0.000e+00 1.000e+00 2.000e+00\n",
      "  0.000e+00 9.460e+02 1.200e+01]\n",
      " [0.000e+00 0.000e+00 2.000e+00 0.000e+00 4.000e+00 1.000e+00 0.000e+00\n",
      "  3.000e+00 0.000e+00 9.940e+02]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.720e+02, 1.000e+00, 1.000e+00, 0.000e+00, 0.000e+00, 1.000e+00,\n",
       "        1.000e+00, 0.000e+00, 0.000e+00, 2.000e+00],\n",
       "       [0.000e+00, 1.124e+03, 2.000e+00, 3.000e+00, 1.000e+00, 1.000e+00,\n",
       "        0.000e+00, 1.000e+00, 0.000e+00, 0.000e+00],\n",
       "       [0.000e+00, 1.000e+00, 1.026e+03, 0.000e+00, 4.000e+00, 0.000e+00,\n",
       "        0.000e+00, 1.000e+00, 0.000e+00, 0.000e+00],\n",
       "       [0.000e+00, 0.000e+00, 3.000e+00, 1.005e+03, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 1.000e+00, 1.000e+00, 0.000e+00],\n",
       "       [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 9.730e+02, 0.000e+00,\n",
       "        2.000e+00, 0.000e+00, 0.000e+00, 4.000e+00],\n",
       "       [1.000e+00, 0.000e+00, 2.000e+00, 1.100e+01, 1.000e+00, 8.690e+02,\n",
       "        1.000e+00, 1.000e+00, 0.000e+00, 6.000e+00],\n",
       "       [3.000e+00, 2.000e+00, 1.000e+00, 1.000e+00, 3.000e+00, 1.000e+00,\n",
       "        9.450e+02, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "       [1.000e+00, 0.000e+00, 5.000e+00, 1.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 1.013e+03, 0.000e+00, 8.000e+00],\n",
       "       [5.000e+00, 0.000e+00, 6.000e+00, 1.000e+00, 0.000e+00, 1.000e+00,\n",
       "        2.000e+00, 0.000e+00, 9.460e+02, 1.200e+01],\n",
       "       [0.000e+00, 0.000e+00, 2.000e+00, 0.000e+00, 4.000e+00, 1.000e+00,\n",
       "        0.000e+00, 3.000e+00, 0.000e+00, 9.940e+02]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train('./MNIST_Data')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
